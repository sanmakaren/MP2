library(broom)
# Load all your packages here:
library(tidyverse)
library(scales)
library(MLmetrics)
library(broom)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
glimpse(sample_submission)
#variables:   Categorical - BldgType,  Numerical - GrLivArea
# training <- training %>%
#   select(Id, GrLivArea, BldgType, SalePrice)
# test <- test %>%
#   select(Id, GrLivArea, BldgType)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="Id")
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
rmsle(predicted_points_1$SalePrice , predicted_points_1$.fitted)
