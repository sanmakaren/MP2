broom::augment(newdata = mtcars_test)
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = training)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = test)
predicted_points_1
rmsle(model_1, test)
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = training)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = test)
predicted_points_1
rmsle(predicted_points_1, test)
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = training)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = test)
predicted_points_1
rmse(predicted_points_1, test)
View(training)
glimpse(training)
View(test)
glimpse(test)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="ID")
View(training)
glimpse(training)
View(test)
glimpse(test)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="Id")
View(training)
glimpse(training)
View(test)
glimpse(test)
set.seed(76)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="Id")
mtcars_test <- mtcars %>%
anti_join(mtcars_train, by="ID")
View(fake_train)
# Load all your packages here:
library(tidyverse)
library(scales)
library(Metrics)
library(broom)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
glimpse(sample_submission)
#variables:   Categorical - BldgType,  Numerical - GrLivArea
training <- training %>%
select(Id, GrLivArea, BldgType, SalePrice)
test <- test %>%
select(Id, GrLivArea, BldgType)
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
rmse(predicted_points_1, fake_test)
rmse(predicted_points_1, fake_test$SalePrice)
predicted_points_1
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
rmsle(.fitted,SalePrice)
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
predicted_points_1 %>%
rmsle(.fitted,SalePrice)
rmsle(predicted_points_1$.fitted,predicted_points_1$SalePrice)
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType + OverallQual + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_2 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_2 <- model_2 %>%
broom::augment()
fitted_points_2
# 2.c) Extract model summary info
model_2 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_2 <- model_2 %>%
broom::augment(newdata = fake_test)
predicted_points_2
rmsle(predicted_points_2$.fitted, predicted_points_2$SalePrice)
rmsle(predicted_points_1$.fitted , predicted_points_1$SalePrice)
# Load all your packages here:
library(tidyverse)
library(scales)
library(Metrics)
library(broom)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
glimpse(sample_submission)
#variables:   Categorical - BldgType,  Numerical - GrLivArea
# training <- training %>%
#   select(Id, GrLivArea, BldgType, SalePrice)
# test <- test %>%
#   select(Id, GrLivArea, BldgType)
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
rmsle(predicted_points_1$.fitted , predicted_points_1$SalePrice)
submission <- sample_submission %>%
mutate(SalePrice = mean(training$SalePrice))
write_csv(submission, path = "data/submission_mvp.csv")
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType + OverallQual + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_2_formula, data = fake_train)
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType  + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_2_formula, data = fake_train)
# Load all your packages here:
library(tidyverse)
library(scales)
library(Metrics)
library(broom)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
glimpse(sample_submission)
#variables:   Categorical - BldgType,  Numerical - GrLivArea
# training <- training %>%
#   select(Id, GrLivArea, BldgType, SalePrice)
# test <- test %>%
#   select(Id, GrLivArea, BldgType)
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
rmsle(predicted_points_1$.fitted , predicted_points_1$SalePrice)
submission <- sample_submission %>%
mutate(SalePrice = mean(training$SalePrice))
write_csv(submission, path = "data/submission_mvp.csv")
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType + OverallQual + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_2_formula, data = fake_train)
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType + OverallQual + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_2_formula, data = fake_train)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
View(training)
glimpse(training)
View(test)
glimpse(test)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="Id")
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType + OverallQual + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_2_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_2 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_2 <- model_2 %>%
broom::augment()
fitted_points_2
# 2.c) Extract model summary info
model_2 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_2 <- model_2 %>%
broom::augment(newdata = fake_test)
predicted_points_2
View(training)
#glimpse(training)
View(test)
#glimpse(test)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="Id")
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType + OverallQual + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_2_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_2 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_2 <- model_2 %>%
broom::augment()
fitted_points_2
# 2.c) Extract model summary info
model_2 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_2 <- model_2 %>%
broom::augment(newdata = fake_test)
predicted_points_2
rmsle(predicted_points_2$.fitted, predicted_points_2$SalePrice)
rmsle(predicted_points_2$.SalePrice, predicted_points_2$.fitted)
rmsle(predicted_points_1$SalePrice , predicted_points_1$.fitted)
?rmsle
summary(model_2)
rmsle(predicted_points_2$SalePrice, predicted_points_2$.fitted)
# Load all your packages here:
library(tidyverse)
library(scales)
library(MLmetrics)
install.packages("MLmetrics")
# Load all your packages here:
library(tidyverse)
library(scales)
library(MLmetrics)
library(broom)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
glimpse(sample_submission)
#variables:   Categorical - BldgType,  Numerical - GrLivArea
# training <- training %>%
#   select(Id, GrLivArea, BldgType, SalePrice)
# test <- test %>%
#   select(Id, GrLivArea, BldgType)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="Id")
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
rmsle(predicted_points_1$SalePrice , predicted_points_1$.fitted)
# Load all your packages here:
library(tidyverse)
library(scales)
library(MLmetrics)
library(broom)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
glimpse(sample_submission)
#variables:   Categorical - BldgType,  Numerical - GrLivArea
# training <- training %>%
#   select(Id, GrLivArea, BldgType, SalePrice)
# test <- test %>%
#   select(Id, GrLivArea, BldgType)
fake_train <- training %>%
sample_frac(0.75)
fake_test <- training %>%
anti_join(fake_train, by="Id")
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice~ GrLivArea + BldgType")
model_1 <- lm(model_1_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_1 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
broom::augment()
fitted_points_1
# 2.c) Extract model summary info
model_1 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
broom::augment(newdata = fake_test)
predicted_points_1
RMSLE(predicted_points_1$SalePrice , predicted_points_1$.fitted)
submission <- sample_submission %>%
mutate(SalePrice = mean(training$SalePrice))
write_csv(submission, path = "data/submission_mvp.csv")
# 1. Fit model to training data
model_2_formula <- as.formula("SalePrice~ GrLivArea + BldgType + OverallQual + HalfBath + Foundation + SaleCondition")
model_2 <- lm(model_2_formula, data = fake_train)
# 2.a) Extract regression table with confidence intervals
model_2 %>%
broom::tidy(conf.int = TRUE)
# 2.b) Extract point-by-point info of points used to fit model
fitted_points_2 <- model_2 %>%
broom::augment()
fitted_points_2
# 2.c) Extract model summary info
model_2 %>%
broom::glance()
# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_2 <- model_2 %>%
broom::augment(newdata = fake_test)
predicted_points_2
# HAVE TO LOG BEFORE FITTING AND UNLOG AFTER PREDICTING
RMSLE(predicted_points_2$SalePrice, predicted_points_2$.fitted)
submission <- sample_submission %>%
mutate(SalePrice = mean(training$SalePrice))
write_csv(submission, path = "data/submission_due_diligence.csv")
submission <- sample_submission %>%
mutate(SalePrice = mean(training$SalePrice))
write_csv(submission, path = "data/submission_reach_for_stars.csv")
submission <- sample_submission %>%
mutate(SalePrice = mean(training$SalePrice))
write_csv(submission, path = "data/submission_diminishing_returns.csv")
RMSLE(predicted_points_2$SalePrice, predicted_points_2$.fitted)
RMSLE(predicted_points_2$SalePrice , predicted_points_2$.fitted)
